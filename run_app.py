import json
from dotenv import load_dotenv
from openai import OpenAI
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain.output_parsers import PydanticOutputParser
from utils import ainvoke_graph, astream_graph
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, END, START
from langgraph.prebuilt import create_react_agent
from typing import TypedDict, List, Dict, Any, Annotated, Literal, Optional
import operator
import re

load_dotenv()

# ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
# model = OpenAI(
#         base_url="http://localhost:8000/v1",
#         api_key="token",  # vLLMì€ API í‚¤ í•„ìš” ì—†ìŒ
#         timeout=600  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
#     )
model = ChatOllama(model="PetrosStav/gemma3-tools:27b", num_ctx=20000, num_predict=1024)
# model = ChatOllama(model="llama3.1:8b", num_ctx=20000, num_predict=1024)
# model = ChatOllama(model="qwen2.5:14b", num_ctx=20000, num_predict=1024)
# model = ChatOpenAI(model="gpt-4o-mini")

# ê° ì—ì´ì „íŠ¸ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜

# MCP ì„¤ì • ê´€ë ¨ í•¨ìˆ˜
def load_mcp_config():
    try:
        with open("./mcp_config.json", "r") as f:
            return json.load(f)
    except Exception as e:
        print(f"ì„¤ì • íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def create_server_config():
    config = load_mcp_config()
    server_config = {}

    if config and "mcpServers" in config:
        for server_name, server_config_data in config["mcpServers"].items():
            if "command" in server_config_data:
                server_config[server_name] = {
                    "command": server_config_data.get("command"),
                    "args": server_config_data.get("args", []),
                    "transport": "stdio",
                }
            elif "url" in server_config_data:
                server_config[server_name] = {
                    "url": server_config_data.get("url"),
                    "transport": "sse",
                }

    return server_config


class AgentState(TypedDict):
        messages: str
        # booking_info: Dict[str, str]
        missing_info: List
        excel_info: str
        available_row: Optional[int]
        generation: str
        formatting: Dict[str, str]
        client: Any
        row: str

def extract_missing_info(state: AgentState):

    prompt = PromptTemplate(
            template="""ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë¥¼ ë°›ì•„ ë³‘ì› ì§„ë£Œ ì˜ˆì•½ì„ ìœ„í•´ ë” í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ìœ ëŠ¥í•œ AI Agent ì…ë‹ˆë‹¤.\n 

            ì œê³µë˜ëŠ” ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n
            {messages}

            Rules
            1. í•„ìˆ˜ í•­ëª©ì€ 'í™˜ìëª…','ìƒë…„ì›”ì¼','ì˜ˆì•½ì¼', 'ì˜ˆì•½ì‹œê°„', 'ì—°ë½ì²˜' ì…ë‹ˆë‹¤.
            2. ì œê³µëœ ì •ë³´ ì¤‘ ê° í•­ëª©ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ í›„ ë‚´ìš©ì´ ì—†ëŠ” í•­ëª©ë“¤ì„ ë‚˜ì—´í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.
            3. ëª¨ë“  í•­ëª©ì´ ì œê³µë˜ì—ˆë‹¤ë©´ ë¹ˆ ë¬¸ìì—´ ""ì„ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì€ í•˜ì§€ë§ˆì„¸ìš”. 
            4. ë¶€ì—°ì„¤ëª…ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”. 

            """,
            input_variables=["messages"],
    )

    # ì—ì´ì „íŠ¸ ìƒì„± ë° í˜¸ì¶œ
    messages = state['messages']
    agent = prompt | model | StrOutputParser()
    
    response = agent.invoke({"messages": messages})
    # print("@@@", state['messages'])
    print("ëˆ„ë½ëœ í•„ìˆ˜ì •ë³´:", response)


    missing = []

    required_fields = ['í™˜ìëª…', 'ìƒë…„ì›”ì¼', 'ì˜ˆì•½ì¼', 'ì˜ˆì•½ì‹œê°„', 'ì—°ë½ì²˜']
    for x in required_fields:
        if x in response:
            missing.append(x)

    return {"messages": messages, "missing_info": missing}


def judge(state: AgentState):

    missing_info = state['missing_info']

    if len(missing_info)>0:
        return "incomplete"
    else:
        return "complete"


def request_info(state: AgentState):
    last_word = state['missing_info'][-1]
    info = ', '.join(state['missing_info'])

    if last_word in ['í™˜ìëª…', 'ìƒë…„ì›”ì¼', 'ì˜ˆì•½ì‹œê°„']:
       generation = f"ì§„ë£Œì˜ˆì•½ì„ ìœ„í•´ì„œëŠ” {info}ì´ í•„ìš”í•©ë‹ˆë‹¤. ì¶”ê°€ ì •ë³´ë¥¼ ë§ì”€í•´ì£¼ì‹œë©´ ì˜ˆì•½ ì§„í–‰ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
    else:
        generation = f"ì§„ë£Œì˜ˆì•½ì„ ìœ„í•´ì„œëŠ” {info}ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì¶”ê°€ ì •ë³´ë¥¼ ë§ì”€í•´ì£¼ì‹œë©´ ì˜ˆì•½ ì§„í–‰ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
    

    return {"messages": state['messages'], "missing_info": state['missing_info'], "generation": generation}


async def read_excel(state: AgentState, client):

    print("------ì˜ˆì•½ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ ì¡°íšŒ ì¤‘ì…ë‹ˆë‹¤------")

    prompt = """ë‹¹ì‹ ì€ 'read_sheet_data' íˆ´ì„ í™œìš©í•˜ì—¬ ì—‘ì…€ ë‚´ìš©ì„ ì½ì–´ì˜¤ëŠ” AI Agentì…ë‹ˆë‹¤.
            ì•„ë˜ ê²½ë¡œì˜ ì—‘ì…€ íŒŒì¼ì—ì„œ ì˜ˆì•½ ì •ë³´ë¥¼ ì½ì–´ì™€ ì£¼ì„¸ìš”.

            íŒŒì¼ ì •ë³´:
            fileAbsolutePath: "C:/Users/kyongjun/Desktop/hospital2.xlsx"
            sheetName: "Sheet1"
            range: "A1:F100"

            ì´ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ read_sheet_data íˆ´ì„ í˜¸ì¶œí•˜ê³  ì•„ë˜ì™€ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì—‘ì…€ ë‚´ìš©ì™€ ë¹„ì–´ìˆëŠ” ê°€ì¥ ìœ— í–‰ì˜ ë²ˆí˜¸ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
            {{"contents": "ì—‘ì…€ ì •ë³´", "row": "ë¹„ì–´ìˆëŠ” ê°€ì¥ ìœ— í–‰ì˜ ë²ˆí˜¸"}}
            ë¶€ê°€ì„¤ëª…ì€ í•˜ì§€ë§ˆì„¸ìš”."""
  
    messages = [
        SystemMessage(content=prompt),
        HumanMessage(content="ì—‘ì…€ íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì™€ì£¼ì„¸ìš”.")
    ]
    
    tools = client.get_tools()
    agent = create_react_agent(model=model, tools=tools, prompt=prompt)
    
    response = await agent.ainvoke({"messages": messages})
    
    # ì‘ë‹µì—ì„œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ì˜ ë‚´ìš©ì„ ì¶”ì¶œ
    if isinstance(response, dict) and "messages" in response:
        last_message = response["messages"][-1]
        content = last_message.content if hasattr(last_message, 'content') else last_message.get("content", "")
        
        # ë§Œì•½ contentê°€ ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ë¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ë¬¸ìì—´ì´ë¼ë©´ JSONìœ¼ë¡œ íŒŒì‹±
        if isinstance(content, dict):
            content_dict = content
        else:
            # JSON ë¬¸ìì—´ì—ì„œ JSON ê°ì²´ ë¶€ë¶„ë§Œ ì¶”ì¶œí•´ì„œ íŒŒì‹±
            try:
                import re
                import json
                # JSON í˜•ì‹ì˜ ë¬¸ìì—´ì„ ì°¾ê¸°
                json_matches = re.search(r'(\{.*\})', content, re.DOTALL)
                if json_matches:
                    json_str = json_matches.group(1)
                    content_dict = json.loads(json_str)
                else:
                    # JSON ë¬¸ìì—´ì´ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ íŒŒì‹± ì‹œë„
                    content_dict = json.loads(content)
            except json.JSONDecodeError:
                return {"messages": state["messages"], "excel_info": "JSON íŒŒì‹± ì‹¤íŒ¨", "generation": "JSON íŒŒì‹± ì‹¤íŒ¨"}
        
        return {"messages": state["messages"], "excel_info": content_dict['contents'], "row": content_dict['row']}
    
    return {"messages": state["messages"], "excel_info": "ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "generation": "ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}


def check_duplicate(state: AgentState):
    

    prompt = PromptTemplate(
            template="""ë‹¹ì‹ ì€ ê³ ê°ì´ ìš”ì²­í•œ ì˜ˆì•½ì •ë³´ì™€ ê¸°ì¡´ ì˜ˆì•½ ê¸°ë¡ë“¤ì„ ë¹„êµí•˜ì—¬ ì¤‘ë³µ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” AI Agentì…ë‹ˆë‹¤.\n
            ì„ ì˜ˆì•½í•œ ê³ ê°ì´ ìˆë‹¤ë©´ í•´ë‹¹ ì‹œê°„ì— ì˜ˆì•½ì„ ì¡ìœ¼ë©´ ì•ˆë˜ë¯€ë¡œ ë§¤ìš° ì¤‘ìš”í•œ ì¼ì…ë‹ˆë‹¤.

            ê³ ê°ì´ ìš”ì²­í•œ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n
            {messages} \n
            ê¸°ì¡´ ì˜ˆì•½ê¸°ë¡ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. \n
            {excel_info}

            ë‹¤ìŒ í”„ë¡œì„¸ìŠ¤ì— ë”°ë¼ ì¶”ë¡ í•˜ì„¸ìš”.
            1. ê³ ê°ì´ ìš”ì²­í•œ ì •ë³´ì—ì„œ ì˜ˆì•½ì¼ìì™€ ì˜ˆì•½ì‹œê°„ì„ í™•ì¸
            2. ë§Œì•½ ê³ ê°ì˜ ì •ë³´ ì¤‘ ë™ì¼ í•­ëª©ì— ëŒ€í•´ 2ê°€ì§€ ì´ìƒì˜ ì •ë³´ê°€ ì£¼ì–´ì§„ë‹¤ë©´ ë” ìµœì‹  ì •ë³´ì¸ ì•„ë˜ìª½ ì •ë³´ë¥¼ í™œìš©í•˜ì„¸ìš”.
            3. ê¸°ì¡´ ì˜ˆì•½ê¸°ë¡ë“¤ë¡œë¶€í„° ì˜ˆì•½ì¼ì ë° ì‹œê°„ í™•ì¸
            4. ê³ ê°ì´ ìš”ì²­í•œ ì‹œê°„ëŒ€ì™€ ê²¹ì¹˜ëŠ” ê¸°ì¡´ ì˜ˆì•½ì´ ìˆëŠ”ì§€ ë¹„êµ
            5. ê²¹ì¹˜ëŠ” ê¸°ì¡´ ì˜ˆì•½ì´ ìˆë‹¤ë©´ "yes"ë¥¼ ì¶œë ¥í•˜ê³ , ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ "no"ë¥¼ ì¶œë ¥. ê·¼ê±°ë¥¼ 1ì¤„ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
            """,
            input_variables=["messages","excel_info"],
    )

    # ì—ì´ì „íŠ¸ ìƒì„± ë° í˜¸ì¶œ
    messages = state['messages']
    excel_info = state['excel_info']
    agent = prompt | model | StrOutputParser()
    
    response = agent.invoke({"messages": messages, "excel_info": excel_info})

    print("ê³ ê° ìš”ì²­:", messages, "\n")
    print("ì—‘ì…€ ë‚´ìš©:", excel_info, "\n")
    print("ì¤‘ë³µ ì—¬ë¶€:", response, "\n")

    if "yes" in response:
        return "yes"
    else:
        return "no"


async def propose_candidate(state: AgentState, client):

    messages = state['messages']
    excel_info = state['excel_info']
    prompt = f"ë‹¹ì‹ ì€ ì„ ì˜ˆì•½ì´ ìˆëŠ” ì‹œê°„ì— ì˜ˆì•½ì„ ìš”ì²­í•œ ê³ ê°ì—ê²Œ ê°€ëŠ¥í•œ ì‹œê°„ëŒ€ë¥¼ ì œì‹œí•´ì£¼ëŠ” ì¹œì ˆí•œ AI Agentì…ë‹ˆë‹¤.\n \
                ê³ ê°ì´ ìš”ì²­í•œ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n \
                {messages} \n \
                ê¸°ì¡´ ì˜ˆì•½ê¸°ë¡ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. \n \
                {excel_info} \n \n\
                ë‹¤ìŒ í”„ë¡œì„¸ìŠ¤ì— ë”°ë¼ ì¶”ë¡ í•˜ì„¸ìš”. \n \
                1. ê³ ê°ì´ ìš”ì²­í•œ ì •ë³´ì—ì„œ ì˜ˆì•½ì¼ìì™€ ì˜ˆì•½ì‹œê°„ì„ í™•ì¸ \n\
                2. ì—‘ì…€íŒŒì¼ì— ê¸°ë¡ëœ ì˜ˆì•½ê¸°ë¡ë“¤ë¡œë¶€í„° ì´ë¯¸ ì˜ˆì•½ëœ ì¼ì ë° ì‹œê°„ì„ í™•ì¸ \n\
                3. ê¸°ì¡´ ì˜ˆì•½ë“¤ê³¼ ê²¹ì¹˜ì§€ ì•Šìœ¼ë©´ì„œ ê³ ê°ì´ ìš”ì²­í•œ ì˜ˆì•½ê³¼ ìœ ì‚¬í•œ ì‹œê°„ëŒ€ë¥¼ ì œì‹œ."
    
    inputs = [
        SystemMessage(content=prompt),
    ]
    
    tools = client.get_tools()
    agent = create_react_agent(model=model, tools=tools, prompt=prompt)
    
    response = await agent.ainvoke({"messages": inputs})
    
    # ì‘ë‹µì—ì„œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ì˜ ë‚´ìš©ì„ ì¶”ì¶œ
    if isinstance(response, dict) and "messages" in response:
        last_message = response["messages"][-1]
        content = last_message.content if hasattr(last_message, 'content') else last_message.get("content", "")

        return {"messages": state["messages"], "excel_info": excel_info, "generation": content}


def get_format(state: AgentState):

    prompt = PromptTemplate(
            template="""ë‹¹ì‹ ì€ ê³ ê°ì´ ìš”ì²­í•œ ì •ë³´ë¥¼ ì •í•´ì§„ ì–‘ì‹ì— ë§ê²Œ ì¬êµ¬ì„±í•˜ëŠ” ìœ ëŠ¥í•œ AI Agentì…ë‹ˆë‹¤.\n
            ê³ ê°ì´ ìš”ì²­í•œ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì•„ë˜ìª½ì˜ ì •ë³´ê°€ ë” ìµœì‹ ì •ë³´ì…ë‹ˆë‹¤.
            {messages} 
            ìœ„ ì •ë³´ë¡œë¶€í„° 'í™˜ìëª…', 'ìƒë…„ì›”ì¼', 'ì˜ˆì•½ì¼', 'ì˜ˆì•½ì‹œê°„', 'ì—°ë½ì²˜', 'ë¹„ê³ 'ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n
            


            Example: 
            {{"í™˜ìëª…": "ìµœë¯¼í˜¸", "ìƒë…„ì›”ì¼": "1994-05-16", "ì˜ˆì•½ì¼": "2025-04-19", "ì˜ˆì•½ì‹œê°„": "15:00", "ì—°ë½ì²˜": "010-5464-8977", "ë¹„ê³ ": ""}}    
            
            Rules
            1. JSON ì–‘ì‹ì„ ê¼­ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ë§¤ìš° ì¤‘ìš”í•œ ê·œì¹™ì…ë‹ˆë‹¤.
            2. ë¶€ê°€ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
            3. ì˜ˆì‹œì—ì„œ ë³´ì—¬ì¤€ ì–‘ì‹ì„ ì¤€ìˆ˜í•˜ì„¸ìš”.
            4. íŠ¹ì • í•­ëª©ì˜ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì˜ˆì‹œì˜ 'ë¹„ê³ 'ì™€ ê°™ì´ ë¹ˆ ë¬¸ìì—´ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”.
            5. ê°™ì€ í•­ëª©ì— ëŒ€í•´ 2ê°œ ì´ìƒì˜ ì •ë³´ê°€ ìˆë‹¤ë©´ ë” ìµœì‹  ì •ë³´ì¸ ì•„ë˜ìª½ ì •ë³´ë¥¼ë¥¼ ë°˜ì˜í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.
            
            """,
            input_variables=["messages"],
    )

    # ì—ì´ì „íŠ¸ ìƒì„± ë° í˜¸ì¶œ
    messages = state['messages']

    agent = prompt | model | JsonOutputParser()
    
    response = agent.invoke({"messages": messages})

    new_format = {"data": [[]], "fileAbsolutePath":  "C:/Users/kyongjun/Desktop/hospital2.xlsx", "range": f"A{state['row']}:F{state['row']}", "sheetName": "Sheet1"}
    for vals in response.values():
        new_format['data'][0].append(vals)
    

    # print("ì–‘ì‹ ì„¤ì • ê²°ê³¼:", str(new_format))

    return {"messages": messages, "formatting": str(new_format)}



async def write_excel(state: AgentState, client):

    print("------ì˜ˆì•½ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤------")

    prompt = ""
  
    messages = [
        HumanMessage(content="'write_sheet_data' íˆ´ì„ í™œìš©í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì—‘ì…€ì— ì‘ì„±í•˜ì„¸ìš”."),
        HumanMessage(content=state['formatting'])
    ]
    
    tools = client.get_tools()
    agent = create_react_agent(model=model, tools=tools, prompt=prompt)
    
    response = await agent.ainvoke({"messages": messages})
    
    # ì‘ë‹µì—ì„œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ì˜ ë‚´ìš©ì„ ì¶”ì¶œ
    if isinstance(response, dict) and "messages" in response:
        last_message = response["messages"][-1]
        content = last_message.content if hasattr(last_message, 'content') else last_message.get("content", "")
        # print("ì—‘ì…€ ì‘ì„± ê²°ê³¼:", content)

        return {"messages": state["messages"], "excel_info": content, "generation": "ì˜ˆì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!"}
    
    return {"messages": state["messages"], "generation": "ì˜ˆì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!"}




# ê·¸ë˜í”„ êµ¬ì„±
async def build_agent_graph():

    server_config = create_server_config()
    
    client = MultiServerMCPClient(server_config)

    await client.__aenter__()

    # ì´ˆê¸° ìƒíƒœì— client í¬í•¨
    initial_state = {"messages": "", "missing_info": [], "excel_info": "", "available_row": None, "generation": "", "client": client}

    async def read_excel_wrapper(state):
        return await read_excel(state, client)
    
    async def propose_candidate_wrapper(state):
        return await propose_candidate(state, client)

    async def write_excel_wrapper(state):
        return await write_excel(state, client)

    
    # ê·¸ë˜í”„ ìƒì„±
    workflow = StateGraph(AgentState)
    
    # ë…¸ë“œ ì¶”ê°€ - ë¹„ë™ê¸° ë˜í¼ í•¨ìˆ˜ ì‚¬ìš©
    workflow.add_node("extract_missing_info", extract_missing_info)
    # workflow.add_node("judge", judge_node)
    workflow.add_node("read_excel", read_excel_wrapper)
    workflow.add_node("request_info", request_info)
    workflow.add_node("propose_candidate", propose_candidate_wrapper)
    workflow.add_node("get_format", get_format)
    workflow.add_node("write_excel", write_excel_wrapper)
    
    # ì—£ì§€ ì¶”ê°€
    workflow.add_edge(START, "extract_missing_info")
    workflow.add_conditional_edges("extract_missing_info",
                    judge,
                    {
                        "complete": "read_excel",
                        "incomplete": "request_info",
                    },
                    )
    workflow.add_edge("request_info", END)
    workflow.add_conditional_edges("read_excel",
                        check_duplicate,
                        {"yes": "propose_candidate",
                        "no": "get_format"}
                        )
    workflow.add_edge("propose_candidate", END)
    workflow.add_edge("get_format", "write_excel")
    workflow.add_edge("write_excel", END)

    return workflow.compile(), initial_state 


async def interactive_chat():
    graph, initial_state = await build_agent_graph()
    
    print("ë³‘ì› ì˜ˆì•½ ë„ìš°ë¯¸ì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥)")
    messages = ""
    
    # initial_stateì—ì„œ state ì´ˆê¸°í™”
    state = initial_state.copy()

    while True:

        query = input("\nğŸ’¬ ì‚¬ìš©ì ì…ë ¥: ")
        
        if query.lower() in ["exit", "quit"]:
            print("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
        try:
            # ê·¸ë˜í”„ ì‹¤í–‰
            messages += f" {query}"
            state["messages"] = messages
            
            # ìƒíƒœë¥¼ ì§ì ‘ ì „ë‹¬
            response = await graph.ainvoke(state)
            # print("@@@", response)
            print(f"\nğŸ¤– {response['generation']}")
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            state = response
            messages = response['messages']
            
            # ì˜ˆì•½ ì™„ë£Œ ì‹œ ë©”ì‹œì§€ ì´ˆê¸°í™”
            if response['generation'] == "ì˜ˆì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!":
                messages = ""
                
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    import asyncio
    asyncio.run(interactive_chat())



